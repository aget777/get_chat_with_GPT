{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55cc3761",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from IPython.display import Audio\n",
    "from pathlib import Path\n",
    "\n",
    "import mysql.connector as connection\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pyodbc\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "from func_MySQL_DB import *\n",
    "import config \n",
    "\n",
    "# забираем токен chatGPT из файла config\n",
    "api_key = config.chat_gpt_api_key\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "# забираем параметры подключения к БД\n",
    "server = config.server\n",
    "port = config.port\n",
    "database = config.database\n",
    "user_name = config.login\n",
    "password = config.password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca01eae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b911c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию для подключения к Базе данных\n",
    "# она принимает на входе\n",
    "# server - адрес сервера\n",
    "# port - номер порта(опционально), по умолчанию используем 3306\n",
    "# database - название базы данных\n",
    "# user_name - логин\n",
    "# password - пароль\n",
    "\n",
    "def get_db_connection(server, database, user_name, password, port='3306'):\n",
    "    mysql_uri = 'mysql+pymysql://'+user_name+':'+password+'@'+server+ ':'+ port +'/'+database\n",
    "    db = SQLDatabase.from_uri(mysql_uri)\n",
    "    \n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9302a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# получаем схему Базы данных\n",
    "# функция внутри себя создает подключение с нашей БД с данными\n",
    "def get_schema(_):\n",
    "    db = get_db_connection(server, database, user_name, password, port)\n",
    "    return db.get_table_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615bb8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию, чтобы на основе человеческого вопроса создать SQL запрос\n",
    "# на входе она принимает\n",
    "# user_question - обычный вопрос человеческим языком, касающийся данных в Базе\n",
    "# model_name - название модели GPT(опционально). По умолчанию используем - gpt-3.5-turbo\n",
    "def get_sql_chain(user_question, model_name='gpt-3.5-turbo'):\n",
    "#     создаем шаблон запроса, чтобы chatGPT понял, что от него хотят\n",
    "    template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "    {schema}\n",
    "\n",
    "    Question: {question}\n",
    "    SQL Query:\"\"\"\n",
    "# формируем Объект promt\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "# создаем объект Языковой модели, чтобы она преобразовала человечексий вопрос в SQL запрос\n",
    "    llm = ChatOpenAI(model_name=model_name)\n",
    "    \n",
    "# создаем звено для получения ответа на человеческий вопрос\n",
    "# get_schema - запрашиваем схему БД\n",
    "# prompt - отправляем шаблон запроса\n",
    "# llm.bind(stop=\"\\nSQLResult:\") - забираем ответ после этих слов\n",
    "# StrOutputParser() - выводим ответ на печать\n",
    "\n",
    "    sql_chain = (\n",
    "        RunnablePassthrough.assign(schema=get_schema)\n",
    "       | prompt\n",
    "        | llm.bind(stop=\"\\nSQLResult:\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "# sql_chain.invoke - отправляем вопрос и получаем ответ   \n",
    "    return sql_chain.invoke({\"question\": user_question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb198b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию, которая получает SQL запрос и отправляет его в нашу БД\n",
    "# SQL запрос формируется автоматически из человеческого запроса\n",
    "def run_query(query):\n",
    "    db = get_db_connection(server, database, user_name, password, port)\n",
    "    return db.run(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797206d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию для получения человеческого ответа на вопрос, касающийся БД\n",
    "# на вход она принимает вопрос в обычном человеческом виде\n",
    "# отправляет его в БД -> получает SQL запрос ->\n",
    "# -> отправляет его в БД -> получает ответ от БД ->\n",
    "# -> интерпретирует его в обычную человеческий ответ по данным из БД\n",
    "\n",
    "def get_db_answer(user_question, model_name='gpt-3.5-turbo'):\n",
    "    \n",
    "#     создаем языковую модель на SQL запрос\n",
    "    llm = ChatOpenAI(model_name='gpt-3.5-turbo')\n",
    "#   создаем шаблон запроса, чтобы chatGPT понял, что от него хотят  \n",
    "    template = \"\"\"Based on the table schema below, write a SQL query that would answer the user's question:\n",
    "    {schema}\n",
    "\n",
    "    Question: {question}\n",
    "    SQL Query:\"\"\"\n",
    "# формируем Объект promt\n",
    "    prompt = ChatPromptTemplate.from_template(template)\n",
    "    \n",
    "# создаем звено для получения ответа на человеческий вопрос\n",
    "# get_schema - запрашиваем схему БД\n",
    "# prompt - отправляем шаблон запроса\n",
    "# llm.bind(stop=\"\\nSQLResult:\") - забираем ответ после этих слов\n",
    "# StrOutputParser() - выводим ответ на печать\n",
    "\n",
    "    sql_chain = (\n",
    "        RunnablePassthrough.assign(schema=get_schema)\n",
    "       | prompt\n",
    "        | llm.bind(stop=\"\\nSQLResult:\")\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "    \n",
    "#     создаем языковую модель для интерпритации данных из БД    \n",
    "    llm2 = ChatOpenAI(model_name=model_name)\n",
    "    \n",
    "#   создаем шаблон запроса, чтобы chatGPT понял, что от него хотят \n",
    "    template2 = \"\"\"Based on the table schema below, question, sql query, and sql response, \n",
    "    write a natural language response on russian language:\n",
    "    {schema}\n",
    "\n",
    "    Question: {question}\n",
    "    SQL Query: {query}\n",
    "    SQL Response: {response}\"\"\"\n",
    "# формируем Объект promt\n",
    "    prompt2 = ChatPromptTemplate.from_template(template2)\n",
    "    \n",
    "# создаем полную цепочку из запросов\n",
    "# на первом шаге вызываем языковую модель для того, чтобы превратить человеческий вопрос в SQL запрос ->\n",
    "# -> В ответ на SQL запрос мы получаем ответ от БД ->\n",
    "# -> его берет другая языковая модель и интерпретирует человеческими словами\n",
    "\n",
    "    full_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "        schema=get_schema,\n",
    "        response=lambda vars: run_query(vars[\"query\"]),)\n",
    "    | prompt2\n",
    "    | llm2\n",
    "    )\n",
    "    \n",
    "    answer = full_chain.invoke({\"question\": user_question})\n",
    "    \n",
    "    return answer.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee6d295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# создаем функцию для преобразования текст в голос\n",
    "# на входе она принимает \n",
    "# - text - текст для озвучки\n",
    "# - file_path - путь для сохранения файла вместе с его названием\n",
    "# - model - указываем модель (по умолчанию 'tts-1')\n",
    "# - voice - указываем название голоса для озвучки (по умолчанию 'onyx')\n",
    "# на выходе сохраняем озвученный файл в папку\n",
    "def get_voice_gpt(text, file_path, model='tts-1', voice='onyx'):\n",
    "#     создаем объект для подключения к чату\n",
    "    client = OpenAI()\n",
    "# создаем АПИ запрос для озвучки\n",
    "    with client.audio.speech.with_streaming_response.create(\n",
    "      model=model,\n",
    "      voice=voice,\n",
    "      input=text\n",
    "    ) as response:\n",
    "        response.stream_to_file(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab189d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_chat(dialog_list, prompt, model='gpt-3.5-turbo'):\n",
    "    client = OpenAI(api_key=api_key)\n",
    "    \n",
    "    dialog_dict = {}\n",
    "    message = [{\"role\": \"user\", \"content\": prompt}]\n",
    "\n",
    "    chat_completion = client.chat.completions.create(\n",
    "    model = model,\n",
    "    messages=message,\n",
    "    temperature=0,\n",
    "    )\n",
    "    \n",
    "    answer = chat_completion.choices[0].message.content\n",
    "    \n",
    "    dialog_dict['question'] = prompt\n",
    "    dialog_dict['answer'] = answer\n",
    "    \n",
    "    dialog_list.append(dialog_dict)\n",
    "\n",
    "    print(f'question:{prompt}')\n",
    "\n",
    "    return answer #chat_completion.choices[0].message.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
